pipeline {
    agent none

    options {
        timeout(time: 1, unit: 'HOURS')
        timestamps()
    }

    environment {
        // AWS
        AWS_DEFAULT_REGION = 'us-west-2'
        AWS_ACCESS_KEY_ID     = credentials('aws-access-key')
        AWS_SECRET_ACCESS_KEY = credentials('aws-secret-key')

        // EKS / App
        CLUSTER_NAME = 'devcluster'
        NAMESPACE = 'devproject'

        // DNS
        DOMAIN_NAME = 'www.cipherworld.shop'
        HOSTED_ZONE_ID = 'Z00868963MIIUG9RNPKSN'
    }

    stages {

        /* ===================== SCM ===================== */
        stage('Checkout') {
            agent { label 'slave' }
            steps {
                git branch: 'dev',
                    credentialsId: 'github',
                    url: 'https://github.com/Sooria16/knote.git'
            }
        }

        /* ===================== CONFIRM ===================== */
        stage('Destroy Confirmation') {
            agent { label 'slave' }
            steps {
                input message: '‚ö†Ô∏è Are you sure you want to DESTROY ALL infrastructure?',
                      ok: 'DESTROY'
            }
        }

        /* ===================== AWS VALIDATION ===================== */
        stage('Validate AWS Access') {
            agent { label 'slave' }
            steps {
                sh 'aws sts get-caller-identity'
            }
        }

        /* ===================== KUBECTL ===================== */
        stage('Configure kubectl') {
            agent { label 'slave' }
            steps {
                sh '''
                    aws eks update-kubeconfig \
                      --region ${AWS_DEFAULT_REGION} \
                      --name ${CLUSTER_NAME} || true

                    kubectl config current-context || true
                    kubectl get nodes || true
                '''
            }
        }

        /* ===================== DELETE APP ===================== */
        stage('Delete Application & K8s Resources') {
            agent { label 'slave' }
            steps {
                sh '''
                    set +e
                    kubectl delete -f kube-cluster/dev/multi-tier/webcon.yaml --ignore-not-found
                    kubectl delete -f kube-cluster/dev/multi-tier/mongodb.yaml --ignore-not-found
                    kubectl delete -f kube-cluster/dev/multi-tier/pvc.yaml --ignore-not-found
                    kubectl delete -f kube-cluster/dev/multi-tier/storageclass.yaml --ignore-not-found
                    kubectl delete -f kube-cluster/dev/ns.yaml --ignore-not-found
                '''
            }
        }

        stage('Delete Ingress Controller') {
            agent { label 'slave' }
            steps {
                sh '''
                    kubectl delete -f kube-cluster/dev/newIngressctrl.yaml --ignore-not-found
                '''
            }
        }

        /* ===================== ROUTE53 ===================== */
        stage('Delete Route53 Record') {
            agent { label 'slave' }
            steps {
                sh '''
                    set +e
                    RECORD_NAME="${DOMAIN_NAME}."

                    RECORD_JSON=$(aws route53 list-resource-record-sets \
                      --hosted-zone-id ${HOSTED_ZONE_ID} \
                      --query "ResourceRecordSets[?Name == '${RECORD_NAME}' && Type == 'CNAME'] | [0]" \
                      --output json)

                    if [ "$RECORD_JSON" = "null" ] || [ -z "$RECORD_JSON" ]; then
                      echo "‚ÑπÔ∏è Route53 record not found, skipping"
                      exit 0
                    fi

                    TTL=$(echo "$RECORD_JSON" | jq -r '.TTL')
                    VALUE=$(echo "$RECORD_JSON" | jq -r '.ResourceRecords[0].Value')

                    cat > route53-delete.json <<EOF
{
  "Changes": [{
    "Action": "DELETE",
    "ResourceRecordSet": {
      "Name": "${RECORD_NAME}",
      "Type": "CNAME",
      "TTL": ${TTL},
      "ResourceRecords": [
        { "Value": "${VALUE}" }
      ]
    }
  }]
}
EOF

                    aws route53 change-resource-record-sets \
                      --hosted-zone-id ${HOSTED_ZONE_ID} \
                      --change-batch file://route53-delete.json
                '''
            }
        }

        /* ===================== EBS CSI CLEANUP ===================== */
        stage('Delete EBS CSI Addon') {
            agent { label 'slave' }
            steps {
                sh '''
                    set +e

                    aws eks describe-addon \
                      --cluster-name ${CLUSTER_NAME} \
                      --addon-name aws-ebs-csi-driver \
                      --region ${AWS_DEFAULT_REGION} >/dev/null 2>&1

                    if [ $? -eq 0 ]; then
                      aws eks delete-addon \
                        --cluster-name ${CLUSTER_NAME} \
                        --addon-name aws-ebs-csi-driver \
                        --region ${AWS_DEFAULT_REGION}

                      aws eks wait addon-deleted \
                        --cluster-name ${CLUSTER_NAME} \
                        --addon-name aws-ebs-csi-driver \
                        --region ${AWS_DEFAULT_REGION}
                    fi

                    STACK_NAME="eksctl-${CLUSTER_NAME}-addon-aws-ebs-csi-driver"

                    aws cloudformation describe-stacks \
                      --stack-name $STACK_NAME \
                      --region ${AWS_DEFAULT_REGION} >/dev/null 2>&1

                    if [ $? -eq 0 ]; then
                      aws cloudformation update-termination-protection \
                        --stack-name $STACK_NAME \
                        --no-enable-termination-protection \
                        --region ${AWS_DEFAULT_REGION}

                      aws cloudformation delete-stack \
                        --stack-name $STACK_NAME \
                        --region ${AWS_DEFAULT_REGION}

                      aws cloudformation wait stack-delete-complete \
                        --stack-name $STACK_NAME \
                        --region ${AWS_DEFAULT_REGION}
                    fi
                '''
            }
        }

        /* ===================== TERRAFORM ===================== */
        stage('Terraform Destroy') {
            agent { label 'slave' }
            steps {
                dir('kube-cluster/dev') {
                    sh '''
                        terraform init -no-color
                        terraform destroy -auto-approve -no-color
                    '''
                }
            }
        }
    }

    post {
        success {
            echo "üß® Infrastructure destroyed successfully"
        }
        failure {
            echo "‚ùå Destroy pipeline failed"
        }
        always {
            echo "üì¶ Destroy pipeline finished"
        }
    }
}
